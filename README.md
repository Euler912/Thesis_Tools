This repository contains an implementation of an algorithm for solving constrained difference-of-convex (DC) optimization problems of the form:

max
â¡
ğ¹
(
ğ‘¥
)
=
ğ‘”
(
ğ‘¥
)
âˆ’
â„
(
ğ‘¥
)
maxF(x)=g(x)âˆ’h(x)
subject to:

ğ·
ğ‘¥
â‰¤
ğ‘‘
,
ğ‘¥
â‰¥
0
Dxâ‰¤d,xâ‰¥0
where 
ğ‘”
(
ğ‘¥
)
g(x) and 
â„
(
ğ‘¥
)
h(x) are convex functions. In our specific example, 
ğ¹
(
ğ‘¥
)
F(x) consists of two quadratic terms, while the constraints are defined by a matrix 
ğ·
D and a vector 
ğ‘‘
d, with all variables being non-negative.

Objective Function
The optimization problem maximizes the function:

max
â¡
ğ‘¥
âˆˆ
ğ‘…
ğ‘›
âˆ‘
ğ‘–
=
1
ğ‘›
(
ğ‘›
âˆ’
1
âˆ’
0.1
ğ‘–
)
ğ‘¥
ğ‘–
2
xâˆˆR 
n
 
max
â€‹
  
i=1
âˆ‘
n
â€‹
 (nâˆ’1âˆ’0.1i)x 
i
2
â€‹
 
This function can be expressed as the difference of two quadratic functions, making it suitable for Difference-of-Convex (DC) optimization techniques. Specifically, we represent it as:

ğ¹
(
ğ‘¥
)
=
ğ‘”
(
ğ‘¥
)
âˆ’
â„
(
ğ‘¥
)
,
F(x)=g(x)âˆ’h(x),
where both 
ğ‘”
(
ğ‘¥
)
g(x) and 
â„
(
ğ‘¥
)
h(x) are convex quadratic functions.

Usage
The provided algorithms are designed to run with 
ğ‘›
=
20
n=20 (i.e., 20 variables). Additionally, a PDF file is included, documenting the results of maximizing the function for different values of 
ğ‘›
n.
